{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuneAI segmentation in XNAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, run the following command from terminal: \n",
    "# /workspace/admin/envs/duneai/etc/activate.d/init.sh\n",
    "# then select 'duneai' kernel from available kernels. Restart notebook if not listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configure and analyze project directories\n",
    "\n",
    "Put XNAT project name where your data resides here. Also some configuration file locations are set here. Intermediate configuration files will be written to your workspace directory/{Project}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, sys\n",
    "#local imports\n",
    "pymipl_path = os.path.abspath(os.path.join('../../','pymipl'))\n",
    "sys.path.append(pymipl_path)\n",
    "sys.path.append( os.path.abspath(pymipl_path+'/xnat_workflow') ) \n",
    "from dicom_sort import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/admin/pymipl/xnat_workflow'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymipl_path+'/xnat_workflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, sys\n",
    "#local imports\n",
    "pymipl_path = os.path.abspath(os.path.join('../../','pymipl'))\n",
    "sys.path.append(pymipl_path)\n",
    "from dicom_sort import *\n",
    "from pathlib import Path\n",
    "\n",
    "#set to True to regenerate project directory structure saved in local json file.\n",
    "rebuild_directory_structure=False\n",
    "\n",
    "#XNAT project label\n",
    "project='RIDER-LUNG-CT'\n",
    "\n",
    "#Persistent workspace root path\n",
    "root_dir=Path(\"/workspace/admin\")\n",
    "\n",
    "local_workdir_path=root_dir / project\n",
    "xnat_project_path=f'/data/projects/{project}/experiments'\n",
    "directory_structure_file=local_workdir_path / \"project_dir_structure.json\"\n",
    "xnat_structure_file=local_workdir_path / \"xnat_structure.json\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scan mounted project directory\n",
    "Project structure, with all DICOM scans and segmentations, is written to  configuration files in workspace project location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if rebuild_directory_structure:\n",
    "    d=analyze_dir(xnat_project_path,directory_structure_file)\n",
    "else:\n",
    "    with open(directory_structure_file, 'r') as file:\n",
    "        d = json.load(file)\n",
    "        \n",
    "subjects=reindex_to_structurals_and_segs(d,xnat_structure_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Detect structural CT scans in data.\n",
    "Build a list of structural CT scans in project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of scans: 59\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "ct_scans=[]\n",
    "for exp in d['children']:\n",
    "    #print (Path(exp['path']).stem)\n",
    "    exp_label=Path(exp['path']).stem\n",
    "    for subdir1 in exp['children']:\n",
    "        if Path(subdir1['path']).stem == 'SCANS': \n",
    "            #print(subdir1['path'])\n",
    "            for scan in subdir1['children']:\n",
    "                scan_label=Path(scan['path']).stem\n",
    "                #print (scan_label)\n",
    "                try:\n",
    "                    #print(scan['children'][0]['children'][0]['SOPClass'])\n",
    "                    if scan['children'][0]['children'][0]['SOPClass']=='CTImageStorage':\n",
    "                        #print('CT image:', scan_label)\n",
    "                        ct_scans+=[scan['children'][0]['children'][0]]\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    \n",
    "print(f'number of scans: {len(ct_scans)}')\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create step descriptors for the XNAT workflow parser.\n",
    "This creates batch files to run on experiment specific containers. Set flags in the beginning to control execution.\n",
    "\n",
    "Performs the following:\n",
    "1. convert strcutrual DICOM's to NIFTI\n",
    "2. convert existing segmentations, if any, to NIFTI\n",
    "3. run AI segmentation\n",
    "4. generate QC images\n",
    "5. compute Dice coefficients.\n",
    "\n",
    "The batch file is then run outside of this notebook by external containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Import workflow adapter. The initial workflow is defined in a dictionary with 'steps' and substitution metadata, and saved \n",
    "#in yaml format. The adapter reads the dictionaries and convert them to batch files, to be executed in local environment.\n",
    "from workflow_adapters import workflow_to_batch, init_global_vars_bootstrap_image, sync_resource_xnat\n",
    "\n",
    "#2. Set up environment for the generated batch scripts. Two types of environment are supported.  \n",
    "\n",
    "#Global workflow environment variables.\n",
    "#Put here variables that may be used in step commands, but are not step or job dependent\n",
    "#These variables have g_ prefix when used in step commands.\n",
    "global_vars={}\n",
    "\n",
    "# a) jupyter notebook: scripts are executed locally from the same XNAT-Jupyter notebook (suitable for lighweight jobs)\n",
    "env_type='jupyter'\n",
    "\n",
    "# b) XNAT container service: scripts are executed inside bootstrap container, with one container instance per session.\n",
    "env_type='container'\n",
    "\n",
    "# Workflow ID must be unique among project workflows.\n",
    "workflow_id='DuneAI'\n",
    "global_vars['g_workflow_id']=workflow_id\n",
    "\n",
    "if env_type=='jupyter':\n",
    "    pymipl_dir=root_dir / \"pymipl\"\n",
    "    duneai_dir=root_dir / \"DuneAI/AutomaticSegmentationScript\"\n",
    "    #path that mounts directory with XNAT experiments\n",
    "    input_mount_path=xnat_project_path\n",
    "    \n",
    "    global_vars['g_input_mount_path']=input_mount_path\n",
    "    #path to local directory where processing will be stored\n",
    "    global_vars['g_local_workdir_path']=local_workdir_path\n",
    "    #library locations, algorithm specific\n",
    "    global_vars['g_pymipl_dir']=pymipl_dir\n",
    "    #main algorithm repository dir\n",
    "    global_vars['g_alg_repo_dir']=duneai_dir\n",
    "    global_vars['g_project']=project\n",
    "        \n",
    "elif env_type == 'container': #built-in defaults used in the bootstrap image.\n",
    "    init_global_vars_bootstrap_image(global_vars,project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yaml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 120\u001b[39m\n\u001b[32m    117\u001b[39m job[\u001b[33m'\u001b[39m\u001b[33msteps\u001b[39m\u001b[33m'\u001b[39m]=steps\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(job_file_yaml,\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[43myaml\u001b[49m.safe_dump(paths_to_str(job),f,sort_keys=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m env_type==\u001b[33m'\u001b[39m\u001b[33mjupyter\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;66;03m#write all commands to a single batch file\u001b[39;00m\n\u001b[32m    123\u001b[39m     workflow_to_batch(job,global_vars,batch_file)\n",
      "\u001b[31mNameError\u001b[39m: name 'yaml' is not defined"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import yaml\n",
    "\n",
    "def set_logger():\n",
    "    root = logging.getLogger()\n",
    "    root.setLevel(logging.DEBUG)\n",
    "    \n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    root.addHandler(handler)    \n",
    "\n",
    "#helper functions\n",
    "def paths_to_str(x):\n",
    "    if isinstance(x, Path): return str(x)\n",
    "    if isinstance(x, dict): return {k: paths_to_str(v) for k, v in x.items()}\n",
    "    if isinstance(x, list): return [paths_to_str(v) for v in x]\n",
    "    return x\n",
    "\n",
    "def resource_to_xnat(local_resource, xnat_session_resource, xnat_project, xnat_subject, xnat_experiment):\n",
    "    return sync_resource_xnat(local_resource, xnat_session_resource, xnat_project, xnat_subject, xnat_experiment, \\\n",
    "        level=\"experiment\", create_hierarchy=True)\n",
    "\n",
    "\n",
    "#variables prefixed with job_ should be used at the job level; \n",
    "#prefixed with step_ at the step level;\n",
    "#non-prefixed variables are considered general notebook variables not participating in workflow steps.\n",
    "\n",
    "set_logger()\n",
    "\n",
    "#set to True to convert structurals to NIFTI\n",
    "structural2nifti=True\n",
    "#set to True to convert existing RTStruct segmentations to nifti\n",
    "extract_segmentations=False\n",
    "#set to True to run AI segmentation \n",
    "rerun_segmentation=False\n",
    "#set to True to generate QC images\n",
    "rerun_qc=False\n",
    "#set to compute Dice coefficients\n",
    "recompute_dice=False\n",
    "\n",
    "dt=datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "batch_file=local_workdir_path / f\"batch_{dt}.sh\"\n",
    "\n",
    "for scan in ct_scans:\n",
    "    \n",
    "    job={}\n",
    "    steps=[]\n",
    "\n",
    "    #Job-level variables, with 'job_' prefix\n",
    "    \n",
    "    job_dcm_path=Path(scan['path']).parent\n",
    "    job_scan_id=Path(scan['path']).parent.parent.stem\n",
    "    job_subject=scan['PatName']\n",
    "    job_exp_label=Path(scan['path']).parent.parent.parent.parent.stem\n",
    "\n",
    "    # in containers, session is mounted directly to /input\n",
    "    job_scan_context=Path('SCANS') / job_scan_id / 'DICOM' \n",
    "    # in jupyter, we need to prepend experiment name for the correct path to scans.\n",
    "    if env_type == 'jupyter': job_scan_context = Path(job_exp_label) / job_scan_context \n",
    "\n",
    "    \n",
    "    job_out_path=f\"{job_subject}/{job_exp_label}/{job_scan_id}/ct\"\n",
    "    job_title=f'Workflow {workflow_id}, subject {job_subject}, experiment {job_exp_label}, scan {job_scan_id}'\n",
    "    \n",
    "    job['job_title'],job['job_scan_context'],job['job_out_path'],job['job_subject'],job['job_exp_label'],job['job_scan_id']=\\\n",
    "        job_title,job_scan_context,job_out_path,job_subject,job_exp_label,job_scan_id\n",
    "    \n",
    "    job_id=f'{workflow_id}_{job_subject}_{job_exp_label}_{job_scan_id}'\n",
    "    \n",
    "    job_dir=local_workdir_path / 'jobs' / job_id\n",
    "    job_file_yaml=job_dir / 'job.yaml'\n",
    "    job_file_sh=job_dir / 'job.sh'\n",
    "    job_dir.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    #logging.basicConfig(filename=job_file_stem.with_suffix('.log'),encoding=\"utf-8\",filemode=\"a\",\\\n",
    "    #                    format=\"{asctime} - {levelname} - {message}\",\\\n",
    "    #                    style=\"{\",datefmt=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    \n",
    "    #convert structural to NIFTI if not already\n",
    "    #local_data_path is interpreted by the parser.\n",
    "    #input_mount_path is interpreted by the parser.\n",
    "    \n",
    "    if structural2nifti:\n",
    "        step={\"step_title\": \"Convert structural to NIFTI\"}\n",
    "        #specify files/dirs to upload to resource\n",
    "        step['step_upload_files_to_resource']={ 'NIFTI': [ \"{g_local_workdir_path}/{job_out_path}_struct.nii.gz\" ] }\n",
    "        #upload whole dirs to resource <none here>\n",
    "        step['step_command']=\"python {g_pymipl_dir}/test_rt-utils.py {g_input_mount_path}/{job_scan_context} {g_local_workdir_path}/{job_out_path}\"\n",
    "        steps+=[ step ]\n",
    "    \n",
    "    #optionally, convert existing segmentations to NIFTI.\n",
    "    if extract_segmentations:\n",
    "        print (f\"experiment {job_exp_label}, scan {job_scan_id}: converting segmentations to NIFTI\")\n",
    "        for seg in subjects[job_subject]['struct_uids'][scan['SeriesInstanceUID']]['segmentations']:\n",
    "            if seg['SOPClass'] == 'RTStruct':\n",
    "                step={\"step_title\": \"Convert suitable segmentations to NIFTI\"}\n",
    "                step['step_output_resource_name']='NIFTI_SEG'\n",
    "                step['step_upload_to_resource']=True\n",
    "                step['step_seg_path']=seg['path']\n",
    "                step['step_command']=\"python {g_pymipl_dir}/test_rt-utils.py {g_input_mount_path}/{job_scan_context} {g_local_workdir_path}/{job_out_path} --rt_struct_path {g_input_mount_path}/{step_seg_path}\"\n",
    "                steps+=[step]\n",
    "            elif seg['SOPClass'] == 'Seg':\n",
    "                pass #for now\n",
    "\n",
    "    #run segmentation\n",
    "    if rerun_segmentation:\n",
    "        print(f\"experiment {job_exp_label}, scan {job_scan_id}: creating segmentation batch commands\")\n",
    "        step={}        \n",
    "        step['step_outdir']=Path(job_out_path).parent\n",
    "        step['step_command']=\"python {g_alg_repo_dir}/segmentation-cl.py {job_out_path}_struct.nii {step_outdir} {step_outdir}\"\n",
    "        steps+=[ step ]\n",
    "    \n",
    "    #now finish job definition and write the job configuration file.\n",
    "    job['steps']=steps\n",
    "    \n",
    "    with open(job_file_yaml,\"w\") as f:\n",
    "        yaml.safe_dump(paths_to_str(job),f,sort_keys=False)\n",
    "        \n",
    "    if env_type=='jupyter': #write all commands to a single batch file\n",
    "        workflow_to_batch(job,global_vars,batch_file)\n",
    "        \n",
    "    else: #one batch file per job\n",
    "        #create batch        \n",
    "        print(job_file_sh)\n",
    "        #reset job script\n",
    "        ! truncate -s 0 {job_file_sh}\n",
    "        #generate job script\n",
    "        workflow_to_batch(job,global_vars,job_file_sh)\n",
    "        ! chmod +x {job_file_sh}\n",
    "        #store batch file.\n",
    "        print('sending batch to xnat resource')\n",
    "        res=resource_to_xnat(job_dir, job_id, project, job_subject, job_exp_label)\n",
    "        if res == 0:\n",
    "            print('Success')\n",
    "        else: \n",
    "            print (f'Failed sending configuration to session resource, error {res}')\n",
    "        break\n",
    "    continue\n",
    "    \n",
    "    #break #dev mode DEBUG\n",
    "    \n",
    "    duneai_out=out_path.parent / f\"{job_scan_id}_duneai\"\n",
    "    #create QC\n",
    "    if rerun_qc or not (duneai_out / \"qc.png\").exists():\n",
    "        print(f\"experiment {job_exp_label}, scan {job_scan_id}: creating QC batch commands\")\n",
    "        #get the first (and only) matching manual contour file\n",
    "        mask3_param=\"\"\n",
    "        mask3=None\n",
    "        for p in out_path.parent.glob(\"ct_roi_GTVp_*test_man.nii\"):\n",
    "            mask3=p.resolve()\n",
    "            mask3_param=f\"--mask3 {mask3.as_posix()}\"\n",
    "            break\n",
    "        #print(f\"python {(pymipl_dir / 'show_overlays.py')} -o {duneai_out / 'qc.png'} {mask3_param} {duneai_out / 'image.nii'} {duneai_out / 'lung_mask.nii'} {duneai_out / 'DL_mask.nii'} \")\n",
    "        ! echo \"python {(pymipl_dir / 'show_overlays.py')} --palette green,red,lightblue -o {duneai_out / 'qc.png'} {mask3_param} {duneai_out / 'image.nii'} {duneai_out / 'lung_mask.nii'} {duneai_out / 'DL_mask.nii'} \" >> {batch_file}\n",
    "        if mask3 is not None:\n",
    "            ! echo \"python {(pymipl_dir / 'show_overlays.py')} --palette green,lightblue,red -o {duneai_out / 'qc_man.png'} {duneai_out / 'image.nii'} {duneai_out / 'lung_mask.nii'} {mask3} \" >> {batch_file}\n",
    "\n",
    "    #compute Dice\n",
    "    if recompute_dice:\n",
    "        print(f\"experiment {job_exp_label}, scan {job_scan_id}: Dice computation commands\")\n",
    "        man_mask=None\n",
    "        for p in out_path.parent.glob(\"ct_roi_GTVp_*test_man.nii\"):\n",
    "            man_mask=p.resolve()\n",
    "            break\n",
    "        print (f\"python {pymipl_dir / 'compare_masks.py'} --mask1 {man_mask} --mask2 {duneai_out / 'DL_mask.nii'} --out {out_path.parent / 'man2AI.json'}\")\n",
    "        ! echo \"python {pymipl_dir / 'compare_masks.py'} --mask1 {man_mask} --mask2 {duneai_out / 'DL_mask.nii'} --out {out_path.parent / 'man2AI.json'}\" >> {batch_file}\n",
    "\n",
    "    #break #DEBUG\n",
    "\n",
    "if env_type=='jupyter':\n",
    "    print(batch_file)\n",
    "    ! chmod +x {batch_file}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Review QC.\n",
    "Run this cell to review generated QC images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. Collect qc.png and qc_man.png files\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "qc_entries = []\n",
    "\n",
    "for scan in ct_scans:\n",
    "    scan_id = Path(scan['path']).parent.parent.stem\n",
    "    exp_label = Path(scan['path']).parent.parent.parent.parent.stem\n",
    "    subject = scan['PatName']\n",
    "    \n",
    "    out_path = outdir / f\"{subject}/{exp_label}/{scan_id}/ct\"\n",
    "    duneai_out = out_path.parent / f\"{scan_id}_duneai\"\n",
    "\n",
    "    auto_qc = duneai_out / \"qc.png\"\n",
    "    man_qc  = duneai_out / \"qc_man.png\"\n",
    "\n",
    "    if auto_qc.exists():\n",
    "        qc_entries.append(\n",
    "            {\n",
    "                \"subject\": subject,\n",
    "                \"exp\": exp_label,\n",
    "                \"scan_id\": scan_id,\n",
    "                \"auto_path\": auto_qc,\n",
    "                \"man_path\": man_qc if man_qc.exists() else None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "if not qc_entries:\n",
    "    raise ValueError(\"No qc.png files found.\")\n",
    "\n",
    "qc_entries = sorted(qc_entries, key=lambda x: (x[\"subject\"], x[\"exp\"], x[\"scan_id\"]))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. Widgets\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "idx = 0\n",
    "\n",
    "label = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Status:\",\n",
    "    layout=widgets.Layout(width=\"600px\"),\n",
    ")\n",
    "\n",
    "auto_img_widget = widgets.Output()\n",
    "man_img_widget  = widgets.Output()\n",
    "\n",
    "legend = widgets.HTML(\n",
    "    value=\"\"\"\n",
    "    <div style='font-size:14px; margin-top:10px;'>\n",
    "        <b>Legend:</b>\n",
    "        <span style=\"color:green; font-weight:bold;\">green</span>: lung,\n",
    "        <span style=\"color:lightblue; font-weight:bold;\">lightblue</span>: manual,\n",
    "        <span style=\"color:red; font-weight:bold;\">red</span>: duneai\n",
    "    </div>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "btn_prev = widgets.Button(description=\"Prev\")\n",
    "btn_next = widgets.Button(description=\"Next\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3. Display logic\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "def show_image(widget, path):\n",
    "    max_wid=1200\n",
    "    widget.clear_output(wait=True)\n",
    "    if path is not None and Path(path).exists():\n",
    "        with widget:\n",
    "            #display(HTML(f\"<img src='{path.as_posix()}' width='600'>\"))\n",
    "            img=Image.open(path)\n",
    "            display(img.resize((max_wid, int(max_wid * img.height / img.width))))\n",
    "                    \n",
    "    else:\n",
    "        with widget:\n",
    "            display(widgets.HTML(\n",
    "                \"<div style='width:300px; height:40px; text-align:center; color:#888;'>no qc_man</div>\"\n",
    "            ))\n",
    "\n",
    "def show_entry(i):\n",
    "    entry = qc_entries[i]\n",
    "    label.value = f\"Subject: {entry['subject']}, experiment: {entry['exp']}, scan: {entry['scan_id']}\"\n",
    "    show_image(auto_img_widget, entry[\"auto_path\"])\n",
    "    show_image(man_img_widget, entry[\"man_path\"])\n",
    "\n",
    "def on_prev(_):\n",
    "    global idx\n",
    "    idx = max(0,idx - 1)\n",
    "    show_entry(idx)\n",
    "\n",
    "def on_next(_):\n",
    "    global idx\n",
    "    idx = min(len(qc_entries)-1,idx + 1)\n",
    "    show_entry(idx)\n",
    "\n",
    "btn_prev.on_click(on_prev)\n",
    "btn_next.on_click(on_next)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4. Layout\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "buttons = widgets.HBox([btn_prev, btn_next])\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    label,\n",
    "    auto_img_widget,\n",
    "    man_img_widget,\n",
    "    legend,\n",
    "    buttons,\n",
    "])\n",
    "\n",
    "display(ui)\n",
    "show_entry(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate summary statistics. \n",
    "This cell computes Dice coefficient between reference and automatic labels, and shows summary plots across all run sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "\n",
    "#read Dice across the project into array.\n",
    "dice=[]\n",
    "for scan in ct_scans:\n",
    "    dcm_path=(Path(xnat_project_path) / scan['path']).parent\n",
    "    scan_id=Path(scan['path']).parent.parent.stem\n",
    "    exp_label=Path(scan['path']).parent.parent.parent.parent.stem\n",
    "    #print(exp_label)\n",
    "    subject=scan['PatName']\n",
    "    out_path=outdir / f\"{subject}/{exp_label}/{scan_id}/ct\"\n",
    "    try:        \n",
    "        with open(out_path.parent / \"man2AI.json\") as txt:\n",
    "            #print (out_path.parent / \"man2AI.json\")\n",
    "            d=json.load(txt)\n",
    "            #print(d)\n",
    "        dice+=[d['dice']]\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dice_arr = np.array(dice, dtype=float)\n",
    "nonzero = dice_arr[dice_arr != 0]\n",
    "\n",
    "# ---- STATISTICS ----\n",
    "print(\"Count:\", len(dice_arr))\n",
    "print(\"Mean:\", np.mean(dice_arr))\n",
    "print(\"Median:\", np.median(dice_arr))\n",
    "print(\"Min:\", np.min(dice_arr))\n",
    "print(\"Max:\", np.max(dice_arr))\n",
    "print(\"Non-zero count:\", len(nonzero))\n",
    "print(\"Non-zero mean:\", np.mean(nonzero) if len(nonzero) else None)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "# ---- HARD-CODED Y-LIMITS WITH EXTRA SPACE ----\n",
    "# Add small margins above 1 and below 0\n",
    "ymin, ymax = -0.1, 1.1\n",
    "\n",
    "# ---- FIRST BOX PLOT (all data) ----\n",
    "axes[0].boxplot(dice_arr, vert=True, showfliers=True)\n",
    "axes[0].set_title(\"All values\")\n",
    "axes[0].set_ylim(ymin, ymax)\n",
    "axes[0].set_xticks([1])\n",
    "axes[0].set_xticklabels([\"Dice\"])\n",
    "axes[0].set_ylabel(\"Value\")\n",
    "\n",
    "# Annotate percentiles (Q1, median, Q3, max) â€” no min annotation\n",
    "p = np.percentile(dice_arr, [25, 50, 75, 100])\n",
    "labels = [\"Q1\", \"Median\", \"Q3\", \"Max\"]\n",
    "\n",
    "for val, lab in zip(p, labels):\n",
    "    axes[0].annotate(f\"{lab}: {val:.3f}\",\n",
    "                     xy=(1.05, val),\n",
    "                     xytext=(20, 0),\n",
    "                     textcoords=\"offset points\",\n",
    "                     va='center')\n",
    "\n",
    "# ---- SECOND BOX PLOT (non-zero) ----\n",
    "axes[1].boxplot(nonzero, vert=True, showfliers=True)\n",
    "axes[1].set_title(\"Non-zero values\")\n",
    "axes[1].set_ylim(ymin, ymax)\n",
    "axes[1].set_xticks([1])\n",
    "axes[1].set_xticklabels([\"Dice>0\"])\n",
    "axes[1].set_ylabel(\"Value\")\n",
    "\n",
    "# Annotate all percentiles including min for non-zero case\n",
    "p_nz = np.percentile(nonzero, [0, 25, 50, 75, 100])\n",
    "labels_nz = [\"Min\", \"Q1\", \"Median\", \"Q3\", \"Max\"]\n",
    "\n",
    "for val, lab in zip(p_nz, labels_nz):\n",
    "    axes[1].annotate(f\"{lab}: {val:.3f}\",\n",
    "                     xy=(1.05, val),\n",
    "                     xytext=(20, 0),\n",
    "                     textcoords=\"offset points\",\n",
    "                     va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
